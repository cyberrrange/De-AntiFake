# De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks
This is the official code implementation of paper *De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks*.
by _Wei Fan, Kejiang Chen, Chang Liu, Weiming Zhang, and Nenghai Yu_ 
In [International Conference on Machine Learning (ICML) 2025](https://icml.cc/Conferences/2025).

## Introduction

In this repository, we provide the complete code for training and testing the Purification and Refinement model. 

## Model files
The parameter files for the Purification and Refinement model used in our work are available at _PlaceHolder_.

Visit our [website](https://de-antifake.github.io/) for audio samples.

## Acknowledgments

Part of our code were based on several open-source repositories, including [DiffWave](https://github.com/philsyn/DiffWave-unconditional), [AudioPure](https://github.com/cychomatica/AudioPure), [DualPure](https://github.com/Sec4ai/DualPure), [StoRM](https://github.com/sp-uhh/storm) and [DMSE4TTS](https://github.com/dmse4tts/DMSE4TTS). Their code served as a foundation for portions of our experiments.

## Citation
If you find this work useful, please consider citing our paper:
```
@inproceedings{de-antifake-icml2025,
  title = {De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks},
  author = {Fan, Wei and Chen, Kejiang and Liu, Chang and Zhang, Weiming and Yu, Nenghai},
  booktitle = {International Conference on Machine Learning},
  year = {2025},
}
```
